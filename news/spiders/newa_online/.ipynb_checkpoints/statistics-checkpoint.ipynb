{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f832d736-66d7-41ec-bf0c-8dc36b1c22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb2ecdb130e971",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49f71e1bf597cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a019bc25-be48-43e3-bb32-ca5490db3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {os.path.splitext(os.path.basename(f))[0] : pd.read_csv(f) for f in glob.glob('*.csv')} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c043d51a-2a21-44cd-90be-1818f9cd971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86203\n",
      "100516\n",
      "90935\n",
      "337191\n",
      "81629\n",
      "980097\n",
      "23665\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "word_counts = []\n",
    "\n",
    "for name in dataframes:\n",
    "    if name:\n",
    "        dataframe = dataframes[name]\n",
    "        categories.append(name)\n",
    "        dataframe['number_of_words'] = dataframe['final_news'].apply(lambda n: len(n.split()))\n",
    "        total_number_of_words = dataframe['number_of_words'].sum()\n",
    "        print(total_number_of_words)\n",
    "        word_counts.append(total_number_of_words)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05b2fec2-d3ff-4fd5-b3b7-763cd7fd143f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Number of Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>कासा</td>\n",
       "      <td>86203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>अन्तर्राष्ट्रिय</td>\n",
       "      <td>100516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>राजनीति</td>\n",
       "      <td>90935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>बिचा</td>\n",
       "      <td>337191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>मनोरन्जन</td>\n",
       "      <td>81629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>राष्ट्रिय</td>\n",
       "      <td>980097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>अपराध</td>\n",
       "      <td>23665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Category  Number of Words\n",
       "0             कासा            86203\n",
       "1  अन्तर्राष्ट्रिय           100516\n",
       "2          राजनीति            90935\n",
       "3             बिचा           337191\n",
       "4         मनोरन्जन            81629\n",
       "5        राष्ट्रिय           980097\n",
       "6            अपराध            23665"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating a DataFrame\n",
    "dict = {'Category' : categories,\n",
    "        'Number of Words' : word_counts \n",
    "       }\n",
    "df = pd.DataFrame(dict)\n",
    "  \n",
    "# displaying the DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8eab5af3-2a57-41c5-aaa0-62114dc1d565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741\n",
      "986\n",
      "900\n",
      "473\n",
      "448\n",
      "8294\n",
      "257\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "sentence_count = []\n",
    "\n",
    "for name in dataframes:\n",
    "    if name:\n",
    "        dataframe = dataframes[name]\n",
    "        categories.append(name)\n",
    "        dataframe['number_of_sentences'] = dataframe['final_news'].apply(lambda n: len(n.split(\"|\")))\n",
    "        total_number_of_sentence = dataframe['number_of_sentences'].sum()\n",
    "        print(total_number_of_sentence)\n",
    "        sentence_count.append(total_number_of_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c1790c1-5dcd-4f26-ad21-c6febb461a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Number of Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>कासा</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>अन्तर्राष्ट्रिय</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>राजनीति</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>बिचा</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>मनोरन्जन</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>राष्ट्रिय</td>\n",
       "      <td>8294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>अपराध</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Category  Number of Sentences\n",
       "0             कासा                  741\n",
       "1  अन्तर्राष्ट्रिय                  986\n",
       "2          राजनीति                  900\n",
       "3             बिचा                  473\n",
       "4         मनोरन्जन                  448\n",
       "5        राष्ट्रिय                 8294\n",
       "6            अपराध                  257"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating a DataFrame\n",
    "dict = {'Category' : categories,\n",
    "        'Number of Sentences' : sentence_count \n",
    "       }\n",
    "df = pd.DataFrame(dict)\n",
    "  \n",
    "# displaying the DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85d5c7b6-255b-4307-99a6-14639b66f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f887fb94-bab5-4f48-88d3-b07e193848fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_sentence = final_df['number_of_sentences'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "711f659e-c6a7-4360-9eb3-4ae26360048a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12099"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number_of_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff8f2cdd-f8a4-4adc-be72-4539fb48b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_word = final_df['number_of_words'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e922bf7-0fde-42fa-9dcd-9febc624369b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1700236"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number_of_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "07958f89-78e8-4e42-8114-35250098a744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Number of Words</th>\n",
       "      <th>Total Number of Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1700236</td>\n",
       "      <td>12099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Number of Words  Total Number of Sentences\n",
       "0                1700236                      12099"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating a DataFrame\n",
    "dict = {\n",
    "    'Total Number of Words' : [total_number_of_word],\n",
    "    'Total Number of Sentences' : [total_number_of_sentence] \n",
    "}\n",
    "df = pd.DataFrame(dict)\n",
    "  \n",
    "# displaying the DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adfba129-0602-4d2b-87d0-d17a516ffa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location: knowledgable-facts.csv\n",
      "Location: कासा.csv\n",
      "Location: दुर्घटना-अपराध.csv\n",
      "Location: अन्तर्राष्ट्रिय.csv\n",
      "Location: नेवाः.csv\n",
      "Location: बजाः.csv\n",
      "Location: स्थानिय-समाज.csv\n",
      "Location: राजनीति.csv\n",
      "Location: कला.csv\n",
      "Location: राष्ट्रिय.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import glob  \n",
    "from pathlib import Path  \n",
    "  \n",
    "  \n",
    "  \n",
    "# use glob to get all the csv files  \n",
    "# in the folder \n",
    "path = os.getcwd() \n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\")) \n",
    "  \n",
    "  \n",
    "# loop over the list of csv files \n",
    "for f in csv_files: \n",
    "      \n",
    "    # read the csv file \n",
    "    df = pd.read_csv(f) \n",
    "      \n",
    "    df['date'] = df['additional_info'].apply(lambda x: x.split('|', 1)[1])\n",
    "    df['author'] = df['additional_info'].apply(lambda x: x.split('|', 1)[0])\n",
    "    df.drop(['additional_info'], axis=1, inplace=True)\n",
    "    print('Location:', f.split(\"/\")[-1]) \n",
    "    filename = f.split(\"/\")[-1]\n",
    "    filepath = Path(f'./processed/{filename}')  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    df.to_csv(filepath, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b63e38d-3be1-4e27-9971-6c9bce6e039d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (0.0.2)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from langchain-openai) (0.1.10)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from langchain-openai) (1.26.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.6.1 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from langchain-openai) (1.6.1)\n",
      "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from langchain-openai) (0.5.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (3.7.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (0.0.80)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (1.9.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.6.1->langchain-openai)\n",
      "  Using cached httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: sniffio in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2023.10.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain-openai) (2.10)\n",
      "Requirement already satisfied: exceptiongroup in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain-openai) (1.0.4)\n",
      "Requirement already satisfied: certifi in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain-openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain-openai)\n",
      "  Using cached httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain-openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.7->langchain-openai) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.7->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.7->langchain-openai) (2.14.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.7->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/prajwalshrestha/miniconda3/envs/lab/lib/python3.9/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.7->langchain-openai) (1.26.18)\n",
      "Using cached httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: h11, httpcore, httpx\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.9.0\n",
      "    Uninstalling h11-0.9.0:\n",
      "      Successfully uninstalled h11-0.9.0\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 0.9.1\n",
      "    Uninstalling httpcore-0.9.1:\n",
      "      Successfully uninstalled httpcore-0.9.1\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.13.3\n",
      "    Uninstalling httpx-0.13.3:\n",
      "      Successfully uninstalled httpx-0.13.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "googletrans 4.0.0rc1 requires httpx==0.13.3, but you have httpx 0.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018ac5a9-8edc-4e08-be3d-7c2ca18f23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "446c0ac4-03e0-4a44-a132-35829ea73635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23cff405-9967-4d0e-9fc7-92b7dcb0fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class date converter from Bikram Sambat to Gregorian Calendar. I just want the result no any other texts.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43d0a4b1-5a5f-49a5-9de1-7db0037f8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd3dbf24-ca62-49e4-81c1-a7bc2ca1ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./processed/कासा.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3d8ad9d-bd5e-4cfa-9306-e95311dd7926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>final_news</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>युएई वनीगु नेपाली क्रिकेट टिमय् सन्दीप लामिछान...</td>\n",
       "      <td>आईसीसी क्रिकेट विश्वकप लिग टु या युएईइ जुइगु क...</td>\n",
       "      <td>https://www.newaonlinenews.com//%E0%A4%AF%E0%A...</td>\n",
       "      <td>२०७९ फाल्गुण ११, बिहिबार १६:१७:५८</td>\n",
       "      <td>नेवा: अनलाइन न्युज – ललेन्द्र शाक्य</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  युएई वनीगु नेपाली क्रिकेट टिमय् सन्दीप लामिछान...   \n",
       "\n",
       "                                          final_news  \\\n",
       "0  आईसीसी क्रिकेट विश्वकप लिग टु या युएईइ जुइगु क...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.newaonlinenews.com//%E0%A4%AF%E0%A...   \n",
       "\n",
       "                                   date                                author  \n",
       "0   २०७९ फाल्गुण ११, बिहिबार १६:१७:५८    नेवा: अनलाइन न्युज – ललेन्द्र शाक्य   "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fbb6e1d-3b8a-48bc-86a4-f37dedb88dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'March 24, 2023, Thursday 16:17:58'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"२०७९ फाल्गुण ११, बिहिबार १६:१७:५८\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eae2f97a-5836-4a0c-9712-40a94e8a7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import glob  \n",
    "from pathlib import Path  \n",
    "  \n",
    "  \n",
    "  \n",
    "# use glob to get all the csv files  \n",
    "# in the folder \n",
    "path = os.getcwd() \n",
    "csv_files = glob.glob(os.path.join(path, \"processed/*.csv\")) \n",
    "  \n",
    "  \n",
    "# loop over the list of csv files \n",
    "for f in csv_files: \n",
    "      \n",
    "    # read the csv file \n",
    "    df = pd.read_csv(f) \n",
    "      \n",
    "    df['date_processed'] = df['date'].apply(lambda x: chain.invoke({\"input\": x}))\n",
    "    filename = f.split(\"/\")[-1]\n",
    "    filepath = Path(f'./processed/{filename}')  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    df.to_csv(filepath, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "725a2824-a4a9-4dd0-a4e8-08b6907d288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import glob  \n",
    "from pathlib import Path  \n",
    "  \n",
    "  \n",
    "  \n",
    "# use glob to get all the csv files  \n",
    "# in the folder \n",
    "path = os.getcwd() \n",
    "csv_files = glob.glob(os.path.join(path, \"processed/*.csv\")) \n",
    "  \n",
    "  \n",
    "# loop over the list of csv files \n",
    "for f in csv_files: \n",
    "      \n",
    "    # read the csv file \n",
    "    df = pd.read_csv(f) \n",
    "      \n",
    "    df['date'] = df['date_processed']\n",
    "    df.drop(['date_processed'], axis=1, inplace=True)\n",
    "    filename = f.split(\"/\")[-1]\n",
    "    filepath = Path(f'./processed/{filename}')  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    df.to_csv(filepath, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df8d5ca-a835-4466-a26e-4564de097162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "def scrape_article_published_date(url: str) -> str:\n",
    "    # Send an HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "        # Find the meta tag with property='article:published_time'\n",
    "        published_time = soup.find('meta', attrs={'property': 'article:published_time'})\n",
    "    \n",
    "        # Extract the content attribute if the tag is found\n",
    "        if published_time:\n",
    "            date_format = '%m/%d/%Y %I:%M %p'\n",
    "            date_str = published_time.get('content')\n",
    "            if date_str:\n",
    "                parsed_date = datetime.fromisoformat(date_str)\n",
    "                formatted_date = parsed_date.strftime(\"%B %d, %Y %I:%M %p\")\n",
    "                return formatted_date\n",
    "            else:\n",
    "                return ''\n",
    "        else:\n",
    "            return ''\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a88626-ea2f-4408-b421-706c3b7e6e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import glob  \n",
    "from pathlib import Path  \n",
    "import re\n",
    "\n",
    "  \n",
    "# use glob to get all the csv files  \n",
    "# in the folder \n",
    "path = os.getcwd() \n",
    "csv_files = glob.glob(os.path.join(path, \"processed/*.csv\")) \n",
    "  \n",
    "  \n",
    "# loop over the list of csv files \n",
    "for f in csv_files: \n",
    "    filename = f.split(\"/\")[-1]\n",
    "    # read the csv file \n",
    "    filename = f.split(\"/\")[-1]\n",
    "    \n",
    "    print('Started for :', filename)\n",
    "    df = pd.read_csv(f) \n",
    "      \n",
    "    df['date'] = df['url'].apply(lambda x: scrape_article_published_date(x))\n",
    "    print('Location:', filename) \n",
    "    \n",
    "    filepath = Path(f'./processed/{filename}')  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    df.to_csv(filepath, index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
